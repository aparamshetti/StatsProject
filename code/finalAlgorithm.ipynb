{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"../cleaned_train.csv\")\n",
    "df = df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (766871, 57)\n",
      "X_test: (377714, 57)\n",
      "y_train: (766871, 3)\n",
      "y_test: (377714, 3)\n",
      "Locked_X: (563752, 57)\n",
      "Locked_y: (563752, 3)\n",
      "('sum locked: ', 6247.0)\n",
      "('sum train: ', 8406.0)\n",
      "('sum test: ', 3861.0)\n"
     ]
    }
   ],
   "source": [
    "X_train, Locked_X, y_train, Locked_y = train_test_split(df.drop(columns = ['totals.transactionRevenue', 'class_pred', 'fullVisitorId']), df[['totals.transactionRevenue', 'class_pred', 'fullVisitorId']], test_size=0.33, shuffle=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, shuffle = False)\n",
    "print(\"X_train: \" + str(X_train.shape))\n",
    "print(\"X_test: \" + str(X_test.shape))\n",
    "print(\"y_train: \" + str(y_train.shape))\n",
    "print(\"y_test: \" + str(y_test.shape))\n",
    "print(\"Locked_X: \" + str(Locked_X.shape))\n",
    "print(\"Locked_y: \" + str(Locked_y.shape))\n",
    "\n",
    "\n",
    "print(\"sum locked: \", sum(Locked_y['class_pred']))\n",
    "print(\"sum train: \", sum(y_train['class_pred']))\n",
    "print(\"sum test: \", sum(y_test['class_pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1552.81098771 1200.75632511 1031.19128675  873.06689032  849.09972136\n",
      "  555.84804885  546.88567088  528.94351139  495.55638516  450.3575826\n",
      "  439.24008569  425.66397314  401.99561355  381.43843277  372.28267389\n",
      "  365.01160136  356.12259497  348.600143    325.31897493  310.82613346\n",
      "  263.56327102]\n"
     ]
    }
   ],
   "source": [
    "#PCA keeping 95% of variance\n",
    "pca = PCA(.95)\n",
    "\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(pca.singular_values_)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88504601 0.88452571 0.86840777]\n",
      "('Confusion matrix no PCA: ', array([[330147,  43706],\n",
      "       [   111,   3750]]))\n",
      "('f1-score no PCA: ', 0.14615039850341993)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, min_samples_leaf = .1, random_state=0, class_weight='balanced')\n",
    "# rf.fit(X_train, y_train['class_pred'])\n",
    "# y_pred = rf.predict(X_test)\n",
    "print(cross_val_score(rf, X_train, y_train['class_pred'], cv=3))\n",
    "\n",
    "rf.fit(X_train, y_train['class_pred'])\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Confusion matrix no PCA: \", confusion_matrix(y_test['class_pred'], y_pred))\n",
    "print(\"f1-score no PCA: \", f1_score(y_test['class_pred'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Confusion matrix no PCA: ', array([[338678,  35175],\n",
      "       [    78,   3783]]))\n",
      "('f1-score no PCA: ', 0.17669726056190008)\n"
     ]
    }
   ],
   "source": [
    "# print(\"Confusion matrix no PCA: \", confusion_matrix(y_test['class_pred'], y_pred))\n",
    "# print(\"f1-score no PCA: \", f1_score(y_test['class_pred'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90786076 0.90864316 0.90481686]\n",
      "('Confusion matrix PCA: ', array([[330147,  43706],\n",
      "       [   111,   3750]]))\n",
      "('f1-score PCA: ', 0.14615039850341993)\n"
     ]
    }
   ],
   "source": [
    "rf_pca = RandomForestClassifier(n_estimators=100, min_samples_leaf = .1, random_state=0, class_weight='balanced')\n",
    "print(cross_val_score(rf_pca, X_train_pca, y_train['class_pred'], cv=3))\n",
    "\n",
    "rf_pca.fit(X_train_pca, y_train['class_pred'])\n",
    "y_pred_pca = rf_pca.predict(X_test_pca)\n",
    "\n",
    "\n",
    "print(\"Confusion matrix PCA: \", confusion_matrix(y_test['class_pred'], y_pred))\n",
    "print(\"f1-score PCA: \", f1_score(y_test['class_pred'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Lasso/Ridge/RF regression ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Reg = X_test[y_pred_pca ==1]\n",
    "y_Reg = y_test[y_pred_pca == 1]\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_Reg, y_Reg, test_size=0.33, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or train on same training as classification\n",
    "X_train_reg = X_train[y_train['class_pred']==1]\n",
    "y_train_reg = y_train[y_train['class_pred']==1]\n",
    "\n",
    "X_test_reg = X_test[y_pred_pca ==1]\n",
    "y_test_reg = y_test[y_pred_pca == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 100, max_features = 'log2', min_samples_leaf= 0.001) \n",
    "ridge = Ridge(alpha = .202)\n",
    "lasso = Lasso(alpha = 1e-15)\n",
    "\n",
    "rf.fit(X_train_reg, y_train_reg['totals.transactionRevenue'])\n",
    "ridge.fit(X_train_reg, y_train_reg['totals.transactionRevenue'])\n",
    "lasso.fit(X_train_reg, y_train_reg['totals.transactionRevenue'])\n",
    "\n",
    "rf_pred = rf.predict(X_test_reg)\n",
    "ridge_pred = ridge.predict(X_test_reg)\n",
    "lasso_pred = lasso.predict(X_test_reg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = pd.DataFrame({\"random_forest\": rf_pred, \"ridge\": ridge_pred, \"lasso\": lasso_pred}).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Combined: root mean squared error', 282378064.74971926)\n",
      "('RF: root mean squared error', 167974414.1060032)\n",
      "('Ridge: root mean squared error', 339250199.055082)\n",
      "('Lasso:root mean squared error', 401394158.36334455)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "mse_comb=mean_squared_error(y_test_reg['totals.transactionRevenue'], final_pred)\n",
    "rmse_comb=math.sqrt(mse_comb)\n",
    "print(\"Combined: root mean squared error\", rmse_comb)\n",
    "\n",
    "mse_rf=mean_squared_error(y_test_reg['totals.transactionRevenue'], rf_pred)\n",
    "rmse_rf=math.sqrt(mse_rf)\n",
    "print(\"RF: root mean squared error\", rmse_rf)\n",
    "\n",
    "mse_ridge=mean_squared_error(y_test_reg['totals.transactionRevenue'], ridge_pred)\n",
    "rmse_ridge=math.sqrt(mse_ridge)\n",
    "print(\"Ridge: root mean squared error\", rmse_ridge)\n",
    "\n",
    "mse_lasso=mean_squared_error(y_test_reg['totals.transactionRevenue'], lasso_pred)\n",
    "rmse_lasso=math.sqrt(mse_lasso)\n",
    "print(\"Lasso:root mean squared error\", rmse_lasso)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.67974414e+08, 2.82378065e+08, 3.39250199e+08, 4.01394158e+08])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sort([rmse_comb, rmse_rf, rmse_ridge, rmse_lasso])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine results like Kaggle wants\n",
    "\n",
    "#y_test['final_prediction'] = y_pred_pca\n",
    "\n",
    "total_pred = []\n",
    "cnt = 0\n",
    "for x in y_pred_pca: \n",
    "    if x == 0:\n",
    "        total_pred.append(x)\n",
    "    else:\n",
    "        total_pred.append(final_pred[cnt])\n",
    "        cnt +=1\n",
    "        \n",
    "y_test['final_prediction'] = total_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Final prediction per entry: ', 90723344.43640944)\n"
     ]
    }
   ],
   "source": [
    "mse=mean_squared_error(y_test['totals.transactionRevenue'], y_test['final_prediction'])\n",
    "rmse=math.sqrt(mse)\n",
    "print(\"Final prediction per entry: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['totals.transactionRevenue',\n",
       " 'class_pred',\n",
       " 'fullVisitorId',\n",
       " 'final_prediction']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine by User for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = y_test.groupby('fullVisitorId')\n",
    "\n",
    "dfpredictions = group.apply(lambda x: x['final_prediction'].unique())\n",
    "dftrue = group.apply(lambda x: x['totals.transactionRevenue'].unique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4823595352351</th>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196000342279</th>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18672749561458</th>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58970809397690</th>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59381693533730</th>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               predicted   true\n",
       "fullVisitorId                  \n",
       "4823595352351      [0.0]  [0.0]\n",
       "17196000342279     [0.0]  [0.0]\n",
       "18672749561458     [0.0]  [0.0]\n",
       "58970809397690     [0.0]  [0.0]\n",
       "59381693533730     [0.0]  [0.0]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrue.rename(\"true\")\n",
    "concatenated = pd.concat([dfpredictions, dftrue], axis=1)\n",
    "concatenated.rename(columns={0: \"predicted\", 1: \"true\"},inplace = True)\n",
    "concatenated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1\n"
     ]
    }
   ],
   "source": [
    "def sumSeries(df, col):\n",
    "    newCol = []\n",
    "    for x in df[col]:\n",
    "#         print(np.sum(x) + 1)\n",
    "        if np.sum(x) <0:\n",
    "            newCol.append(math.log( 1))\n",
    "        else:\n",
    "            newCol.append(math.log(np.sum(x) + 1))\n",
    "    return newCol\n",
    "\n",
    "concatenated['predicted'] = sumSeries(concatenated, 'predicted')\n",
    "print(\"done 1\")\n",
    "concatenated['true'] = sumSeries(concatenated, 'true')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4269493478\n"
     ]
    }
   ],
   "source": [
    "mse=mean_squared_error(concatenated['true'],concatenated['predicted'])\n",
    "rmse=math.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullVisitorId\n",
       "643479242968736    [0.0, -2403686.6071963185]\n",
       "648792487151265                         [0.0]\n",
       "dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpredictions.iloc[68:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
